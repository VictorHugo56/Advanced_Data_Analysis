# Projeto de An√°lise de Dados: Previs√£o de Churn no E-commerce Brasileiro

## ‚úíÔ∏è Autor
**Victor Hugo**
* **LinkedIn:** [https://www.linkedin.com/in/victor-h-almeida/](https://www.linkedin.com/in/victor-h-almeida/)
* **GitHub:** [https://github.com/VictorHugo56](https://github.com/VictorHugo56)

---

## üéØ Objetivo do Projeto

Este projeto realiza uma an√°lise completa de ponta a ponta sobre um grande conjunto de dados de e-commerce brasileiro, com o objetivo de entender os principais fatores que levam √† evas√£o de clientes (churn) e construir um modelo de machine learning capaz de prever quais clientes est√£o em risco. A an√°lise culmina em um dashboard interativo no Power BI com recomenda√ß√µes estrat√©gicas para o neg√≥cio.

---

## üìä Dashboard Interativo no Power BI

**Clique na imagem abaixo para acessar o dashboard interativo completo publicado na web.**

[![Pr√©via do Dashboard de Churn](images/dashboard_preview.png)](https://app.powerbi.com/view?r=eyJrIjoiNTc1ZjQ1NmMtNWQ2NS00NzBlLWIzYTktZDMwOGZkZjAyYjk3IiwidCI6IjRjNWJlOWYzLWFhYjYtNGQwOS04NmRjLTE4ODlkZTJlYzIxMCJ9)

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagens:** Python, SQL (PostgreSQL)
* **Bibliotecas Python:** Pandas, Matplotlib, Seaborn, Scikit-learn, XGBoost, imbalanced-learn, SHAP
* **Banco de Dados:** PostgreSQL
* **Ferramentas de BI:** Power BI
* **Ambiente:** Jupyter Notebook, VS Code, Git/GitHub

---

## üîÑ Metodologia Anal√≠tica

O projeto foi estruturado em 4 fases principais, seguindo as melhores pr√°ticas de um ciclo de vida de projetos de dados:

### Fase 1: Engenharia de Dados e Ambiente
* **Configura√ß√£o do Ambiente:** Utiliza√ß√£o de um servidor PostgreSQL local para simular um ambiente de produ√ß√£o.
* **Ingest√£o de Dados (ETL):** Desenvolvimento de um script Python (`ingest_data.py`) para automatizar a carga dos m√∫ltiplos arquivos CSV do dataset Olist para o PostgreSQL, tratando erros de codifica√ß√£o e garantindo a integridade dos dados.
* **Consulta Mestra:** Cria√ß√£o de uma query SQL complexa com m√∫ltiplos `LEFT JOINs` para consolidar as informa√ß√µes de 8 tabelas diferentes em uma √∫nica vis√£o, formando a base para a an√°lise.

### Fase 2: An√°lise Explorat√≥ria de Dados (EDA)
Nesta fase, o objetivo foi extrair insights e entender o comportamento do neg√≥cio e dos clientes. As principais an√°lises foram:
* **An√°lise Temporal:** Visualiza√ß√£o do crescimento das vendas e identifica√ß√£o de picos sazonais.
![alt text](images/grafico_pedidos_mensais.png)
* **An√°lise Geogr√°fica:** Mapeamento da concentra√ß√£o de clientes, confirmando o Sudeste como principal mercado.
![alt text](images/grafico_pedidos_por_estado.png)
* **An√°lise de Produtos:** Investiga√ß√£o da din√¢mica "Volume vs. Valor", identificando as categorias que mais vendem contra as que mais faturam.
![alt text](images/graficos_volume_vs_valor.png)
* **An√°lise de Satisfa√ß√£o:** Correla√ß√£o entre atrasos na entrega e notas de avalia√ß√£o, provando que a performance log√≠stica √© um fator cr√≠tico para a satisfa√ß√£o do cliente.
* **An√°lise de Sentimento (NLP):** Uso de Nuvens de Palavras para extrair os principais temas dos coment√°rios de clientes, confirmando que a "entrega" √© o tema central tanto para elogios quanto para reclama√ß√µes.
![alt text](images/nuvens_de_palavras_avaliacoes.png)

### Fase 3: Modelagem Preditiva (Machine Learning)
O objetivo desta fase foi construir um modelo para prever o churn.
* **Engenharia de Caracter√≠sticas:** Cria√ß√£o de features como Rec√™ncia, Frequ√™ncia e Valor (RFM), al√©m da nota m√©dia de avalia√ß√£o e outras m√©tricas comportamentais.
* **Tratamento de Data Leakage:** Identifica√ß√£o e corre√ß√£o de vazamento de dados, removendo a feature `recency` para garantir um modelo preditivo honesto.
* **Modelagem:** Treinamento e avalia√ß√£o de 3 algoritmos de classifica√ß√£o: Regress√£o Log√≠stica, Random Forest e XGBoost.
* **Balanceamento de Classes:** Aplica√ß√£o da t√©cnica SMOTE para lidar com o desbalanceamento entre clientes ativos e churners, melhorando a capacidade do modelo de identificar a classe minorit√°ria.
![alt text](images/matriz_confusao_xgb_smote.png)

### Fase 4: Interpretabilidade e Recomenda√ß√µes
* **Import√¢ncia das Caracter√≠sticas:** Utiliza√ß√£o do modelo treinado para identificar que a **nota m√©dia da avalia√ß√£o** e a **frequ√™ncia de compra** s√£o os fatores mais importantes para prever o churn.
* **Recomenda√ß√µes Estrat√©gicas:** Tradu√ß√£o dos insights em a√ß√µes de neg√≥cio, como focar na otimiza√ß√£o log√≠stica para melhorar a satisfa√ß√£o e criar campanhas de reengajamento para incentivar a segunda compra.

---

## üöÄ Como Executar o Projeto Localmente

1. Clone o reposit√≥rio: `git clone https://github.com/VictorHugo56/Advanced_Data_Analysis.git`
2. Crie e ative um ambiente virtual.
3. Instale as depend√™ncias: `pip install -r requirements.txt`
4. Configure um servidor PostgreSQL e crie um banco de dados vazio.
5. Atualize a string de conex√£o no arquivo `scripts/ingest_data.py` e no notebook com suas credenciais.
6. Execute o script de ingest√£o: `python scripts/ingest_data.py`
7. Abra e execute o notebook `01_Analise_Exploratoria.ipynb`.